# GPU 100 Days Challenge

100ì¼ ë™ì•ˆ CUDA kernelê³¼ Triton kernelì„ ì—°ìŠµí•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

- [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
- [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [100ì¼ ì»¤ë¦¬í˜ëŸ¼](#100ì¼-ì»¤ë¦¬í˜ëŸ¼)
- [ì°¸ê³  ìë£Œ](#ì°¸ê³ -ìë£Œ)

## ğŸš€ ì„¤ì¹˜ ë°©ë²•

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- Python >= 3.11
- CUDA Toolkit (12.6 ì´ìƒ ê¶Œì¥)
- PyTorch 2.7.0
- CMake >= 3.18 (CMake ë¹Œë“œ ì‚¬ìš© ì‹œ)

### ì„¤ì¹˜

1. **ì €ì¥ì†Œ í´ë¡ **

```bash
git clone <repository-url>
cd gpu-100days
```

2. **ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”**

```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv venv
source .venv/bin/activate  # Linux/Mac
# ë˜ëŠ”
.venv\Scripts\activate  # Windows

# ë˜ëŠ” venv ì‚¬ìš©
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
```

3. **ì˜ì¡´ì„± ì„¤ì¹˜ ë° ë¹Œë“œ**

```bash
# uv ì‚¬ìš©
uv sync --no-build-isolation

# ë˜ëŠ” pip ì‚¬ìš©
pip install -e .
```

ë¹Œë“œê°€ ì™„ë£Œë˜ë©´ CUDA í™•ì¥ ëª¨ë“ˆ(`cuda_ops`)ì´ ì„¤ì¹˜ë©ë‹ˆë‹¤.

### ë¹Œë“œ ìºì‹œ ì •ë¦¬ (ë¹Œë“œ ë¬¸ì œ í•´ê²°)

ë¹Œë“œ ì„¤ì •ì„ ë³€ê²½í•œ í›„ì—ëŠ” ê¸°ì¡´ ë¹Œë“œ ìºì‹œë¥¼ ì •ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤:

```bash
# setuptools ë¹Œë“œ ìºì‹œ ì •ë¦¬
rm -rf build/ dist/ *.egg-info
rm -rf src/*.so src/*.egg-info

# CMake ë¹Œë“œ ìºì‹œ ì •ë¦¬ (ì§ì ‘ ë¹Œë“œí•œ ê²½ìš°)
rm -rf csrc/build/

# ì™„ì „íˆ ì¬ë¹Œë“œ
pip install -e . --force-reinstall --no-cache-dir
```

ë˜ëŠ” CMakeë¥¼ ì§ì ‘ ì‚¬ìš©í•œ ê²½ìš°:

```bash
cd csrc/build
rm -rf *
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ..
make
```

### CMakeë¥¼ ì‚¬ìš©í•œ ì§ì ‘ ë¹Œë“œ (ì„ íƒì‚¬í•­)

```bash
cd csrc
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ..
make
```

**ì°¸ê³ **: ë¹Œë“œ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ë‹¤ìŒ ì„¤ì •ì´ ì ìš©ë©ë‹ˆë‹¤:
- Release ëª¨ë“œ ê¸°ë³¸ ì‚¬ìš© (ìµœì í™” í”Œë˜ê·¸ í¬í•¨)
- ë‹¨ì¼ CUDA ì•„í‚¤í…ì²˜ ì»´íŒŒì¼ (sm_86, setup.pyì™€ ì¼ì¹˜)
- ìµœì í™” í”Œë˜ê·¸: `-O3`, `--use_fast_math`

## ğŸ’» ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ

```python
from gpu_100days import vector_add
import torch

# CUDA í…ì„œ ìƒì„±
a = torch.randn(1000, device='cuda', dtype=torch.float32)
b = torch.randn(1000, device='cuda', dtype=torch.float32)

# CUDA ì»¤ë„ì„ ì‚¬ìš©í•œ ë²¡í„° ë§ì…ˆ
c = vector_add(a, b)

# PyTorch ê¸°ë³¸ ì—°ì‚°ê³¼ ë¹„êµ
c_pytorch = a + b
print(torch.allclose(c, c_pytorch))  # True
```

### ì˜ˆì œ ì‹¤í–‰

```bash
python src/gpu_100days/vector_add.py
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
gpu-100days/
â”œâ”€â”€ csrc/                    # CUDA ì†ŒìŠ¤ íŒŒì¼ (.cu)
â”‚   â”œâ”€â”€ CMakeLists.txt       # CMake ë¹Œë“œ ì„¤ì •
â”‚   â”œâ”€â”€ bindings.cu          # CUDA ì»¤ë„ ë°”ì¸ë”©
â”‚   â”œâ”€â”€ vectorAdd.cu         # ë²¡í„° ë§ì…ˆ CUDA ì»¤ë„
â”‚   â”œâ”€â”€ matrixAdd.cu         # í–‰ë ¬ ë§ì…ˆ CUDA ì»¤ë„
â”‚   â””â”€â”€ matrixSub.cu         # í–‰ë ¬ ëº„ì…ˆ CUDA ì»¤ë„
|   â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cuda_ops.pyi         # íƒ€ì… ìŠ¤í… íŒŒì¼
â”‚   â””â”€â”€ gpu_100days/         # Python íŒ¨í‚¤ì§€
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cuda_kernels.py  # CUDA ì»¤ë„ Python ë˜í¼
â”‚       â””â”€â”€ triton_kernels.py # Triton ì»¤ë„ êµ¬í˜„
â”œâ”€â”€ tests/                   # í…ŒìŠ¤íŠ¸ íŒŒì¼
â”‚   â”œâ”€â”€ conftest.py          # pytest ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ test_day1.py         # Day 1 í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_day2.py         # Day 2 í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_day3.py         # Day 3 í…ŒìŠ¤íŠ¸
|   â””â”€â”€ test_dayN.py
â”œâ”€â”€ setup.py                 # setuptools ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ pyproject.toml          # í”„ë¡œì íŠ¸ ì„¤ì •
â””â”€â”€ README.md
```

## ğŸ“š 100ì¼ ì»¤ë¦¬í˜ëŸ¼

ì´ ì»¤ë¦¬í˜ëŸ¼ì€ [100DaysForGPU](https://github.com/mino-park7/100DaysForGPU) ë ˆí¬ì§€í† ë¦¬ë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

### Week 1-2: CUDA ê¸°ì´ˆ (Day 1-14)

| Day | ì£¼ì œ | ë‚´ìš© | ìƒíƒœ |
|-----|------|------|------|
| 1 | ë²¡í„° ì—°ì‚° ê¸°ì´ˆ | Print global indices for 1D vector<br>GPU ë²¡í„° ë§ì…ˆ (ë©”ëª¨ë¦¬ í• ë‹¹, í˜¸ìŠ¤íŠ¸-ë””ë°”ì´ìŠ¤ ì „ì†¡) | [x] |
| 2 | Add matrix | Matrix ë§ì…ˆ CUDA, Triton | [x] |
| 3 | Sub matrix for multiple data type | Matrix ëº„ì…ˆ CUDA, Triton (ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›) | [x] |
| 4 | GrayScaler using CUDA and Triton | RGB imageë¥¼ Gray ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (CUDA, Triton) | [x] |
| 5 | Matrix Multiply | Matrix ê³±ì…ˆ Triton (cuBLASì™€ ì„±ëŠ¥ ë¹„êµ) | [x] |
| 6 | Seeded Dropout | Seeded Dropout CUDA, Triton (ì¬í˜„ ê°€ëŠ¥í•œ ë“œë¡­ì•„ì›ƒ) | [x] |
| 7 | Add Triton for multiple data type | Add ì—°ì‚° Triton (ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›, ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬) | [x] |
| 8 | Matrix Transpose | Matrix ì „ì¹˜ CUDA, Triton (ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›) | [x] |
| 9 | Softmax | Softmax CUDA, Triton (PyTorchì™€ ì„±ëŠ¥ ë¹„êµ) | [x] |
| 10 | Layer Norm Fused | Layer Normalization Fused Triton (Forward/Backward, ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›) | [x] |
| 11 | Flash Attention | Flash Attention Triton (Causal/Non-causal, ë‹¤ì–‘í•œ í—¤ë“œ ì°¨ì› ì§€ì›) | [x] |
| 12 | SiLU (Triton) | SiLU (Sigmoid Linear Unit) Triton (ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›) | [x] |
| 13 | SiLU (CUDA) | SiLU (Sigmoid Linear Unit) CUDA (ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›) | [x] |
| 14 | RoPE (Rotary Position Embedding) | RoPE Triton (ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›, ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬) | [x] |

## ğŸ“– ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [PyTorch C++ Extensions](https://pytorch.org/tutorials/advanced/cpp_extension.html)
- [Triton Documentation](https://triton-lang.org/)

### ì°¸ê³  ë ˆí¬ì§€í† ë¦¬
- [100DaysForGPU](https://github.com/mino-park7/100DaysForGPU) - ì´ í”„ë¡œì íŠ¸ì˜ ì°¸ê³  ë ˆí¬ì§€í† ë¦¬
- [Flash Attention](https://github.com/Dao-AILab/flash-attention)
- [Triton Examples](https://github.com/openai/triton)

### í•™ìŠµ ìë£Œ
- [CUDA by Example](https://developer.nvidia.com/cuda-example)
- [Programming Massively Parallel Processors](https://www.elsevier.com/books/programming-massively-parallel-processors/kirk/978-0-12-811986-0)

## ğŸ› ï¸ ê°œë°œ íŒ

### CUDA ì»¤ë„ì„ PyTorchì— í†µí•©í•˜ëŠ” ë°©ë²•

1. **ì»¤ë„ ì‘ì„±**: `csrc/` ë””ë ‰í† ë¦¬ì— `.cu` íŒŒì¼ ì‘ì„±
2. **ë°”ì¸ë”© ì‘ì„±**: PyTorch í…ì„œë¥¼ ë°›ëŠ” ë˜í¼ í•¨ìˆ˜ ì‘ì„±
3. **Python ë˜í¼**: `src/gpu_100days/`ì— Python ì¸í„°í˜ì´ìŠ¤ ì‘ì„±
4. **ë¹Œë“œ**: `pip install -e .` ë˜ëŠ” `uv sync`ë¡œ ë¹Œë“œ

### ë””ë²„ê¹…

- `compile_commands.json`ì´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì–´ IDEì—ì„œ ì½”ë“œ ì™„ì„± ì§€ì›
- CUDA ì—ëŸ¬ ì²´í¬: `cudaGetLastError()` ì‚¬ìš©
- PyTorch í…ì„œ ê²€ì¦: `TORCH_CHECK` ë§¤í¬ë¡œ ì‚¬ìš©

### ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§

```bash
# Nsight Compute ì‚¬ìš©
ncu --set full python your_script.py

# Nsight Systems ì‚¬ìš©
nsys profile python your_script.py
```
